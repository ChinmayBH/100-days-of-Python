import json
from typing import Any, Dict, List, Optional
import logging
import autogen

from autogen import ConversableAgent, ChatResult
from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent
from langchain_core.messages import HumanMessage, SystemMessage

from backend.config import Config
from backend.models import DBFile
from backend.utils import convert_image_to_base64, get_agent
from backend.llm import get_langchain_models

logger = logging.getLogger(__name__)

class TestCaseGenerator:
    """Test case generator utilities"""
    _screen_shot_analyzer: MultimodalConversableAgent
    _quality_assurance_engineer: ConversableAgent
    _product_manager: ConversableAgent

    def __init__(self, config: Config) -> None:
        self.config = config
        self._init_agents()

    def _init_agents(self) -> None:
        """Initialize the agents"""
        self._screen_shot_analyzer = get_agent(
            agent_config=self.config.get("agents.screenshot_analyser"),
            agent_type="multi-modal"
        )
        self._quality_assurance_engineer = get_agent(
            agent_config=self.config.get("agents.quality_assurance_engineer"),
            agent_type="conversable"
        )
        self._product_manager = get_agent(
            agent_config=self.config.get("agents.product_manager"),
            agent_type="conversable"
        )

    #########################
    def process_doc_data(self, description: str, img: str, icon_dict: Optional[List[DBFile]] = None,
                         previous_analysis: Optional[str] = "", model = None) -> str:
        """
        Process a document description, analyze a screenshot, and generate the corresponding output.
        
        Parameters
        ----------
        description : str
            The description text for the document or screenshot.
        img : str
            The path to the image for processing.
        icon_dict : Optional[List[DBFile]], optional
            List of icon dictionaries for this screenshot, by default [].
        previous_analysis : Optional[str], optional
            Any previous analysis to append to the current analysis, by default "".
        model : optional
            The model to use for analyzing the content.

        Returns
        -------
        str
            The analysis results as a string.
        """
        messages = [
            SystemMessage(
                content=self.config.get(
                    "agents.screenshot_analyser.system_message")
            )
        ]
        if previous_analysis:
            messages.append(HumanMessage(content=[
                {"type": "text",
                 "text": f"Previous screenshot description:\n{previous_analysis}"}
            ]))
        if isinstance(icon_dict, list) and len(icon_dict) > 0:
            icon_img = convert_image_to_base64(str(icon_dict[0].output_file_path))
            messages.append(HumanMessage(
                content=[
                    {"type": "text", "text": str(icon_dict[0].description)},
                    {"type": "image_url", "image_url": {"url": icon_img}},
                ]
            ))

        image_bytes = convert_image_to_base64(img)
        description = description.split("Test Steps:")[-1]
        messages.append(HumanMessage(
                content=[
                    {"type": "text", "text": f"Current screenshot summary: {description}"},
                    {"type": "image_url", "image_url": {"url": image_bytes}},
                ]
            ))

        # Use the model for processing
        response = model.invoke(messages)

        if response is None or response.content is None:
            raise ValueError("Model did not return a valid response")

        return str(response.content)
    #########################

    def _populate_history(self, chat_result: ChatResult) -> None:
        """Populate the chat history with the given chat result."""
        for msg in chat_result.chat_history:
            if msg["name"] == "product_manager":
                self._product_manager.send(
                    msg["content"],
                    self._quality_assurance_engineer,
                    request_reply=False,
                    silent=True
                )
            else:
                self._quality_assurance_engineer.send(
                    msg["content"],
                    self._product_manager,
                    request_reply=False,
                    silent=True)

    def _get_init_chat_params(self, recipient: ConversableAgent, prompt: str,
                              chat_result: Optional[ChatResult] = None) -> Dict[str, Any]:
        """Get the initial chat parameters for a chat session."""
        params = {
            "recipient": recipient,
            "clear_history": False,
            "summary_method": self.config.get("test_case_workflow.summary_method", "last_msg"),
            "summary_args": self.config.get("test_case_workflow.summary_args", {}),
            "max_turns": self.config.get("test_case_workflow.max_turns", 5),
            "chat_history": chat_result.chat_history if chat_result else [],
        }
        if prompt:
            params["message"] = prompt
        termination_message = self.config.get("test_case_workflow.termination_msg")
        if termination_message:
            params["is_termination_msg"] = lambda msg: termination_message.lower() in msg["content"].lower()
        return params

    def generate_test_case(self, files: List[DBFile], prompt: Optional[str] = None,
                           previous_chat_result: Optional[ChatResult] = None) -> ChatResult:
        """Generate a test case based on the given files."""
        if previous_chat_result and prompt:
            logger.info("Restarting previous conversation")
            self._populate_history(previous_chat_result)
            return self._product_manager.initiate_chat(
                **self._get_init_chat_params(
                    recipient=self._quality_assurance_engineer,
                    prompt=prompt,
                    chat_result=previous_chat_result
                ))

        icon_dict = list(filter(lambda f: f.file_type.lower() == "icon dictionary", files))
        test_doc = list(filter(lambda f: f.file_type.lower() == "user story document", files))

        if len(test_doc) == 0:
            raise ValueError("No test case found")

        with open(test_doc[0].output_file_path, "r", encoding="utf-8") as f:
            test_doc_content = json.load(f)

        # Analyze screenshots
        logger.info("SS analysis started")
        formulated_content = []
        ss_analysis = ""
        for content in test_doc_content:
            formulated_content.append(content["text"])
            description = content["text"]
            for img in content.get("image", []):
                #########################
                model = get_langchain_models(self.config.get("agents.screenshot_analyser.llm_config"))  # Initialize model
                ss_analysis = self.process_doc_data(description, img, icon_dict, ss_analysis, model)  # Using process_doc_data
                #########################
                formulated_content.append(ss_analysis)

        logger.info("SS analysis completed.\nTest case generation started")
        logger.info("SS analysis\n-----------------------------------")
        logger.info("\n".join(formulated_content))

        # Generate test case
        autogen.runtime_logging.start(logger_type="file")

        test_case_result = self._product_manager.initiate_chat(
            **self._get_init_chat_params(
                recipient=self._quality_assurance_engineer,
                prompt="\n".join(formulated_content).strip())
        )
        autogen.runtime_logging.stop()

        logger.info("Test case generation completed")
        return test_case_result
